{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dictionary = Dictionary(common_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list=lda.print_topics(num_topics=20,num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.262*\"6\" + 0.262*\"7\" + 0.262*\"3\" + 0.024*\"9\" + 0.024*\"10\" + 0.024*\"1\" + 0.024*\"5\" + 0.024*\"4\" + 0.024*\"8\" + 0.024*\"11\" + 0.024*\"2\" + 0.024*\"0\"'),\n",
       " (1,\n",
       "  '0.339*\"9\" + 0.339*\"10\" + 0.177*\"11\" + 0.016*\"5\" + 0.016*\"7\" + 0.016*\"4\" + 0.016*\"3\" + 0.016*\"8\" + 0.016*\"1\" + 0.016*\"2\" + 0.016*\"0\" + 0.016*\"6\"'),\n",
       " (2,\n",
       "  '0.153*\"7\" + 0.153*\"3\" + 0.153*\"5\" + 0.153*\"6\" + 0.153*\"0\" + 0.153*\"4\" + 0.014*\"9\" + 0.014*\"10\" + 0.014*\"1\" + 0.014*\"11\" + 0.014*\"2\" + 0.014*\"8\"'),\n",
       " (3,\n",
       "  '0.083*\"9\" + 0.083*\"10\" + 0.083*\"1\" + 0.083*\"4\" + 0.083*\"5\" + 0.083*\"0\" + 0.083*\"6\" + 0.083*\"2\" + 0.083*\"7\" + 0.083*\"11\" + 0.083*\"3\" + 0.083*\"8\"'),\n",
       " (4,\n",
       "  '0.337*\"5\" + 0.228*\"8\" + 0.120*\"7\" + 0.120*\"2\" + 0.120*\"1\" + 0.011*\"9\" + 0.011*\"10\" + 0.011*\"3\" + 0.011*\"0\" + 0.011*\"11\" + 0.011*\"4\" + 0.011*\"6\"'),\n",
       " (5,\n",
       "  '0.500*\"9\" + 0.045*\"10\" + 0.045*\"5\" + 0.045*\"2\" + 0.045*\"1\" + 0.045*\"7\" + 0.045*\"3\" + 0.045*\"4\" + 0.045*\"8\" + 0.045*\"0\" + 0.045*\"6\" + 0.045*\"11\"'),\n",
       " (6,\n",
       "  '0.083*\"9\" + 0.083*\"10\" + 0.083*\"7\" + 0.083*\"5\" + 0.083*\"6\" + 0.083*\"11\" + 0.083*\"0\" + 0.083*\"8\" + 0.083*\"2\" + 0.083*\"1\" + 0.083*\"4\" + 0.083*\"3\"'),\n",
       " (7,\n",
       "  '0.262*\"1\" + 0.262*\"2\" + 0.262*\"0\" + 0.024*\"9\" + 0.024*\"10\" + 0.024*\"7\" + 0.024*\"5\" + 0.024*\"4\" + 0.024*\"11\" + 0.024*\"8\" + 0.024*\"6\" + 0.024*\"3\"'),\n",
       " (8,\n",
       "  '0.262*\"11\" + 0.262*\"4\" + 0.262*\"10\" + 0.024*\"9\" + 0.024*\"5\" + 0.024*\"7\" + 0.024*\"2\" + 0.024*\"0\" + 0.024*\"1\" + 0.024*\"3\" + 0.024*\"6\" + 0.024*\"8\"'),\n",
       " (9,\n",
       "  '0.083*\"9\" + 0.083*\"10\" + 0.083*\"5\" + 0.083*\"7\" + 0.083*\"6\" + 0.083*\"4\" + 0.083*\"11\" + 0.083*\"1\" + 0.083*\"2\" + 0.083*\"0\" + 0.083*\"8\" + 0.083*\"3\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mupdate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'symmetric'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mns_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'numpy.float32'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Train and use Online Latent Dirichlet Allocation (OLDA) models as presented in\n",
       "`Hoffman et al. :\"Online Learning for Latent Dirichlet Allocation\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
       "\n",
       "Examples\n",
       "-------\n",
       "Initialize a model using a Gensim corpus\n",
       "\n",
       ".. sourcecode:: pycon\n",
       "\n",
       "    >>> from gensim.test.utils import common_corpus\n",
       "    >>>\n",
       "    >>> lda = LdaModel(common_corpus, num_topics=10)\n",
       "\n",
       "You can then infer topic distributions on new, unseen documents.\n",
       "\n",
       ".. sourcecode:: pycon\n",
       "\n",
       "    >>> doc_bow = [(1, 0.3), (2, 0.1), (0, 0.09)]\n",
       "    >>> doc_lda = lda[doc_bow]\n",
       "\n",
       "The model can be updated (trained) with new documents.\n",
       "\n",
       ".. sourcecode:: pycon\n",
       "\n",
       "    >>> # In practice (corpus =/= initial training corpus), but we use the same here for simplicity.\n",
       "    >>> other_corpus = common_corpus\n",
       "    >>>\n",
       "    >>> lda.update(other_corpus)\n",
       "\n",
       "Model persistency is achieved through :meth:`~gensim.models.ldamodel.LdaModel.load` and\n",
       ":meth:`~gensim.models.ldamodel.LdaModel.save` methods.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "corpus : {iterable of list of (int, float), scipy.sparse.csc}, optional\n",
       "    Stream of document vectors or sparse matrix of shape (`num_terms`, `num_documents`).\n",
       "    If not given, the model is left untrained (presumably because you want to call\n",
       "    :meth:`~gensim.models.ldamodel.LdaModel.update` manually).\n",
       "num_topics : int, optional\n",
       "    The number of requested latent topics to be extracted from the training corpus.\n",
       "id2word : {dict of (int, str), :class:`gensim.corpora.dictionary.Dictionary`}\n",
       "    Mapping from word IDs to words. It is used to determine the vocabulary size, as well as for\n",
       "    debugging and topic printing.\n",
       "distributed : bool, optional\n",
       "    Whether distributed computing should be used to accelerate training.\n",
       "chunksize :  int, optional\n",
       "    Number of documents to be used in each training chunk.\n",
       "passes : int, optional\n",
       "    Number of passes through the corpus during training.\n",
       "update_every : int, optional\n",
       "    Number of documents to be iterated through for each update.\n",
       "    Set to 0 for batch learning, > 1 for online iterative learning.\n",
       "alpha : {numpy.ndarray, str}, optional\n",
       "    Can be set to an 1D array of length equal to the number of expected topics that expresses\n",
       "    our a-priori belief for the each topics' probability.\n",
       "    Alternatively default prior selecting strategies can be employed by supplying a string:\n",
       "\n",
       "        * 'asymmetric': Uses a fixed normalized asymmetric prior of `1.0 / topicno`.\n",
       "        * 'auto': Learns an asymmetric prior from the corpus (not available if `distributed==True`).\n",
       "eta : {float, np.array, str}, optional\n",
       "    A-priori belief on word probability, this can be:\n",
       "\n",
       "        * scalar for a symmetric prior over topic/word probability,\n",
       "        * vector of length num_words to denote an asymmetric user defined probability for each word,\n",
       "        * matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination,\n",
       "        * the string 'auto' to learn the asymmetric prior from the data.\n",
       "decay : float, optional\n",
       "    A number between (0.5, 1] to weight what percentage of the previous lambda value is forgotten\n",
       "    when each new document is examined. Corresponds to Kappa from\n",
       "    `Matthew D. Hoffman, David M. Blei, Francis Bach:\n",
       "    \"Online Learning for Latent Dirichlet Allocation NIPS'10\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
       "offset : float, optional\n",
       "    Hyper-parameter that controls how much we will slow down the first steps the first few iterations.\n",
       "    Corresponds to Tau_0 from `Matthew D. Hoffman, David M. Blei, Francis Bach:\n",
       "    \"Online Learning for Latent Dirichlet Allocation NIPS'10\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
       "eval_every : int, optional\n",
       "    Log perplexity is estimated every that many updates. Setting this to one slows down training by ~2x.\n",
       "iterations : int, optional\n",
       "    Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
       "gamma_threshold : float, optional\n",
       "    Minimum change in the value of the gamma parameters to continue iterating.\n",
       "minimum_probability : float, optional\n",
       "    Topics with a probability lower than this threshold will be filtered out.\n",
       "random_state : {np.random.RandomState, int}, optional\n",
       "    Either a randomState object or a seed to generate one. Useful for reproducibility.\n",
       "ns_conf : dict of (str, object), optional\n",
       "    Key word parameters propagated to :func:`gensim.utils.getNS` to get a Pyro4 Nameserved.\n",
       "    Only used if `distributed` is set to True.\n",
       "minimum_phi_value : float, optional\n",
       "    if `per_word_topics` is True, this represents a lower bound on the term probabilities.\n",
       "per_word_topics : bool\n",
       "    If True, the model also computes a list of topics, sorted in descending order of most likely topics for\n",
       "    each word, along with their phi values multiplied by the feature length (i.e. word count).\n",
       "callbacks : list of :class:`~gensim.models.callbacks.Callback`\n",
       "    Metric callbacks to log and visualize evaluation metrics of the model during training.\n",
       "dtype : {numpy.float16, numpy.float32, numpy.float64}, optional\n",
       "    Data-type to use during calculations inside model. All inputs are also converted.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     LdaMulticore, AuthorTopicModel\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models.LdaModel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
